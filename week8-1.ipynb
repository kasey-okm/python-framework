{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b89ab75",
   "metadata": {},
   "source": [
    "# CORD-19 Metadata Analysis & Streamlit App\n",
    "\n",
    "This notebook guides you through analyzing the CORD-19 metadata and building a simple Streamlit application to present your findings. Follow each section to complete the assignment step-by-step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf497c4",
   "metadata": {},
   "source": [
    "## 1. Install and Import Required Libraries\n",
    "\n",
    "Install the necessary Python packages and import all libraries needed for data analysis and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519273f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If running in a notebook, uncomment and run the following lines to install packages:\n",
    "# !pip install pandas matplotlib seaborn streamlit wordcloud\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import streamlit as st\n",
    "import numpy as np\n",
    "``</VSCode.Cell>\n",
    "\n",
    "<VSCode.Cell language=\"markdown\">\n",
    "## 2. Download and Load the Metadata Dataset\n",
    "\n",
    "Download the `metadata.csv` file from the CORD-19 dataset (Kaggle) and load it into a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33886761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the metadata.csv file (ensure it's in your working directory)\n",
    "df = pd.read_csv('metadata.csv')\n",
    "\n",
    "# Display the shape of the DataFrame\n",
    "print(f\"DataFrame shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd4040c",
   "metadata": {},
   "source": [
    "## 3. Explore Data Structure and Basic Statistics\n",
    "\n",
    "Display the first few rows, check DataFrame shape, column data types, and generate summary statistics for numerical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a298823d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the first 5 rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96644d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check column data types and info\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32ba504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate summary statistics for numerical columns\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984abe1b",
   "metadata": {},
   "source": [
    "## 4. Check and Handle Missing Data\n",
    "\n",
    "Identify columns with missing values, decide on removal or filling strategies, and create a cleaned version of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3dd9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in each column\n",
    "missing_values = df.isnull().sum()\n",
    "print(\"Missing values per column:\\n\", missing_values)\n",
    "\n",
    "# Example: Drop rows where 'title' or 'publish_time' is missing\n",
    "df_clean = df.dropna(subset=['title', 'publish_time'])\n",
    "\n",
    "# Optionally, fill missing abstracts with empty string\n",
    "df_clean['abstract'] = df_clean['abstract'].fillna('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1481703b",
   "metadata": {},
   "source": [
    "## 5. Data Cleaning and Feature Engineering\n",
    "\n",
    "Convert `publish_time` to datetime, extract publication year, and create new columns such as abstract word count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d082da5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert publish_time to datetime\n",
    "df_clean['publish_time'] = pd.to_datetime(df_clean['publish_time'], errors='coerce')\n",
    "\n",
    "# Extract year from publish_time\n",
    "df_clean['year'] = df_clean['publish_time'].dt.year\n",
    "\n",
    "# Create abstract word count column\n",
    "df_clean['abstract_word_count'] = df_clean['abstract'].apply(lambda x: len(str(x).split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b086567",
   "metadata": {},
   "source": [
    "## 6. Analysis: Publications by Year\n",
    "\n",
    "Count the number of papers published each year and prepare data for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b0960a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count papers by publication year\n",
    "year_counts = df_clean['year'].value_counts().sort_index()\n",
    "print(\"Publications by year:\\n\", year_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad10c89",
   "metadata": {},
   "source": [
    "## 7. Analysis: Top Journals\n",
    "\n",
    "Identify and list the top journals publishing COVID-19 research papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8769926d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10 journals by publication count\n",
    "top_journals = df_clean['journal'].value_counts().head(10)\n",
    "print(\"Top journals:\\n\", top_journals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c953321",
   "metadata": {},
   "source": [
    "## 8. Analysis: Frequent Words in Titles\n",
    "\n",
    "Compute word frequency in paper titles using basic text processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbdc0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "# Combine all titles into one string\n",
    "titles = ' '.join(df_clean['title'].dropna().astype(str))\n",
    "\n",
    "# Remove punctuation and split into words\n",
    "words = re.findall(r'\\b\\w+\\b', titles.lower())\n",
    "\n",
    "# Remove common stopwords\n",
    "stopwords = set(STOPWORDS)\n",
    "filtered_words = [word for word in words if word not in stopwords and len(word) > 2]\n",
    "\n",
    "# Count word frequencies\n",
    "word_freq = Counter(filtered_words)\n",
    "print(\"Most common words in titles:\", word_freq.most_common(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bdf1a06",
   "metadata": {},
   "source": [
    "## 9. Visualizations: Publications Over Time\n",
    "\n",
    "Plot the number of publications per year using matplotlib or seaborn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9c4c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "sns.barplot(x=year_counts.index, y=year_counts.values, palette=\"Blues_d\")\n",
    "plt.title('Number of Publications by Year')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of Publications')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4e936c",
   "metadata": {},
   "source": [
    "## 10. Visualizations: Top Journals Bar Chart\n",
    "\n",
    "Create a bar chart showing the top publishing journals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2af7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(x=top_journals.values, y=top_journals.index, palette=\"Greens_d\")\n",
    "plt.title('Top Journals Publishing COVID-19 Research')\n",
    "plt.xlabel('Number of Publications')\n",
    "plt.ylabel('Journal')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0583d694",
   "metadata": {},
   "source": [
    "## 11. Visualizations: Word Cloud of Titles\n",
    "\n",
    "Generate and display a word cloud of the most frequent words in paper titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c437e8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(width=800, height=400, background_color='white', stopwords=STOPWORDS).generate(' '.join(filtered_words))\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title('Word Cloud of Paper Titles')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7729fc07",
   "metadata": {},
   "source": [
    "## 12. Visualizations: Paper Counts by Source\n",
    "\n",
    "Plot the distribution of paper counts by source using a suitable chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605534ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_counts = df_clean['source_x'].value_counts().head(10)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(x=source_counts.values, y=source_counts.index, palette=\"Purples_d\")\n",
    "plt.title('Paper Counts by Source')\n",
    "plt.xlabel('Number of Papers')\n",
    "plt.ylabel('Source')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6532ad02",
   "metadata": {},
   "source": [
    "## 13. Build a Simple Streamlit Application\n",
    "\n",
    "Create a Streamlit app with title, description, interactive widgets, and display the visualizations and sample data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45519874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save this code in a separate file (e.g., streamlit_app.py) to run with Streamlit\n",
    "\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "st.title(\"CORD-19 Data Explorer\")\n",
    "st.write(\"Simple exploration of COVID-19 research papers\")\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('metadata.csv')\n",
    "df['publish_time'] = pd.to_datetime(df['publish_time'], errors='coerce')\n",
    "df['year'] = df['publish_time'].dt.year\n",
    "df['abstract'] = df['abstract'].fillna('')\n",
    "df['abstract_word_count'] = df['abstract'].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "# Interactive year range slider\n",
    "min_year = int(df['year'].min())\n",
    "max_year = int(df['year'].max())\n",
    "year_range = st.slider(\"Select year range\", min_year, max_year, (2020, 2021))\n",
    "\n",
    "filtered_df = df[(df['year'] >= year_range[0]) & (df['year'] <= year_range[1])]\n",
    "\n",
    "st.write(f\"Number of papers from {year_range[0]} to {year_range[1]}: {filtered_df.shape[0]}\")\n",
    "\n",
    "# Publications by year\n",
    "year_counts = filtered_df['year'].value_counts().sort_index()\n",
    "fig, ax = plt.subplots()\n",
    "sns.barplot(x=year_counts.index, y=year_counts.values, ax=ax, palette=\"Blues_d\")\n",
    "ax.set_title('Number of Publications by Year')\n",
    "ax.set_xlabel('Year')\n",
    "ax.set_ylabel('Number of Publications')\n",
    "st.pyplot(fig)\n",
    "\n",
    "# Top journals\n",
    "top_journals = filtered_df['journal'].value_counts().head(10)\n",
    "fig2, ax2 = plt.subplots()\n",
    "sns.barplot(x=top_journals.values, y=top_journals.index, ax=ax2, palette=\"Greens_d\")\n",
    "ax2.set_title('Top Journals Publishing COVID-19 Research')\n",
    "ax2.set_xlabel('Number of Publications')\n",
    "ax2.set_ylabel('Journal')\n",
    "st.pyplot(fig2)\n",
    "\n",
    "# Word cloud of titles\n",
    "titles = ' '.join(filtered_df['title'].dropna().astype(str))\n",
    "words = [word for word in titles.lower().split() if word not in STOPWORDS and len(word) > 2]\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white', stopwords=STOPWORDS).generate(' '.join(words))\n",
    "fig3, ax3 = plt.subplots(figsize=(12,6))\n",
    "ax3.imshow(wordcloud, interpolation='bilinear')\n",
    "ax3.axis('off')\n",
    "st.pyplot(fig3)\n",
    "\n",
    "# Paper counts by source\n",
    "source_counts = filtered_df['source_x'].value_counts().head(10)\n",
    "fig4, ax4 = plt.subplots()\n",
    "sns.barplot(x=source_counts.values, y=source_counts.index, ax=ax4, palette=\"Purples_d\")\n",
    "ax4.set_title('Paper Counts by Source')\n",
    "ax4.set_xlabel('Number of Papers')\n",
    "ax4.set_ylabel('Source')\n",
    "st.pyplot(fig4)\n",
    "\n",
    "# Show sample data\n",
    "st.write(\"Sample of filtered data:\")\n",
    "st.dataframe(filtered_df[['title', 'journal', 'year', 'source_x', 'abstract_word_count']].head(10))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
